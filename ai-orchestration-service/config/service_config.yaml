# AI Orchestration Service Configuration
# =====================================

service:
  name: "ai-orchestration-service"
  version: "1.0.0"
  description: "Enterprise-grade AI orchestration service"
  
  # Service settings
  host: "0.0.0.0"
  port: 8080
  workers: 4
  timeout: 300
  
  # Logging configuration
  logging:
    level: "INFO"
    format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
    file: "logs/ai_orchestration_service.log"
    max_size: "100MB"
    backup_count: 5

# Quantum Orchestrator Configuration
quantum_orchestrator:
  enabled: true
  
  # Quantum algorithm settings
  algorithms:
    qaoa:
      enabled: true
      max_qubits: 20
      optimization_level: 3
      shots: 1024
    vqe:
      enabled: true
      max_qubits: 16
      optimization_level: 2
      shots: 512
    grover:
      enabled: true
      max_qubits: 12
      optimization_level: 2
      shots: 256
  
  # Quantum backend settings
  backends:
    simulator:
      name: "qasm_simulator"
      noise_model: null
      optimization_level: 3
    real_device:
      name: "ibmq_qasm_simulator"
      noise_model: "ibmq_16_melbourne"
      optimization_level: 1
  
  # Performance settings
  performance:
    max_concurrent_tasks: 10
    task_timeout: 300
    memory_limit: "2GB"
    cpu_limit: 4

# Meta-Learning Hub Configuration
meta_learning_hub:
  enabled: true
  
  # Meta-learning algorithms
  algorithms:
    maml:
      enabled: true
      inner_lr: 0.01
      outer_lr: 0.001
      inner_steps: 5
      meta_batch_size: 4
    prototypical_networks:
      enabled: true
      embedding_dim: 64
      distance_metric: "euclidean"
    few_shot_learning:
      enabled: true
      support_shots: [1, 5, 10]
      query_shots: 15
    meta_gradient:
      enabled: true
      gradient_steps: 10
      meta_lr: 0.001
    reptile:
      enabled: true
      inner_lr: 0.01
      outer_lr: 0.001
      inner_steps: 3
    meta_sgd:
      enabled: true
      inner_lr: 0.01
      outer_lr: 0.001
      inner_steps: 5
  
  # Task distribution settings
  task_distribution:
    max_tasks: 1000
    task_timeout: 600
    memory_limit: "1GB"
  
  # Performance settings
  performance:
    max_concurrent_tasks: 5
    evaluation_interval: 60
    metrics_retention_days: 30

# Model Ensemble Configuration
model_ensemble:
  enabled: true
  
  # Ensemble settings
  ensemble:
    max_models: 10
    min_models: 3
    ensemble_type: "weighted_averaging"
    weight_update_frequency: 100
    model_retirement_threshold: 0.1
    ensemble_diversity_threshold: 0.3
  
  # Model types
  model_types:
    neural_network:
      enabled: true
      hidden_size: 256
      dropout: 0.2
    transformer:
      enabled: true
      hidden_size: 256
      num_heads: 8
      num_layers: 4
    quantum_enhanced:
      enabled: true
      quantum_layer_size: 128
      classical_layer_size: 64
    classical_ml:
      enabled: true
      algorithm: "random_forest"
    meta_learning:
      enabled: true
      meta_batch_size: 4
    specialized:
      enabled: true
      specialization_type: "domain_specific"
  
  # Performance settings
  performance:
    max_concurrent_predictions: 20
    prediction_timeout: 30
    memory_limit: "1.5GB"

# Continual Learner Configuration
continual_learner:
  enabled: true
  
  # Continual learning algorithms
  algorithms:
    ewc:
      enabled: true
      lambda_ewc: 1000.0
      fisher_samples: 1000
    gem:
      enabled: true
      memory_size: 1000
      gradient_margin: 0.5
    lwf:
      enabled: true
      temperature: 2.0
      alpha: 0.5
    packnet:
      enabled: true
      pruning_ratio: 0.5
      retraining_epochs: 10
    progressive_networks:
      enabled: true
      lateral_connections: true
      adapter_size: 64
    meta_experience_replay:
      enabled: true
      replay_buffer_size: 10000
      meta_learning_rate: 0.001
  
  # Memory management
  memory:
    episodic_memory_size: 1000
    semantic_memory_size: 500
    procedural_memory_size: 200
    working_memory_size: 10000
    memory_cleanup_interval: 3600  # seconds
  
  # Performance settings
  performance:
    max_concurrent_tasks: 3
    task_timeout: 1800
    forgetting_detection_interval: 60
    memory_limit: "2GB"

# Performance Optimizer Configuration
performance_optimizer:
  enabled: true
  
  # Optimization types
  optimization_types:
    model_optimization:
      enabled: true
      techniques: ["architecture_search", "hyperparameter_tuning", "regularization"]
    inference_optimization:
      enabled: true
      techniques: ["quantization", "pruning", "kernel_optimization"]
    training_optimization:
      enabled: true
      techniques: ["gradient_accumulation", "mixed_precision", "distributed_training"]
    memory_optimization:
      enabled: true
      techniques: ["gradient_checkpointing", "memory_pooling", "model_compression"]
    computational_optimization:
      enabled: true
      techniques: ["operator_fusion", "kernel_optimization", "parallel_computation"]
    quantization:
      enabled: true
      bit_widths: [8, 16, 32]
      techniques: ["post_training_quantization", "quantization_aware_training"]
    pruning:
      enabled: true
      sparsity_levels: [0.1, 0.3, 0.5, 0.7, 0.9]
      techniques: ["structured_pruning", "unstructured_pruning", "magnitude_pruning"]
    distillation:
      enabled: true
      temperature: [1.0, 2.0, 3.0, 4.0, 5.0]
      techniques: ["knowledge_distillation", "feature_distillation", "response_distillation"]
  
  # Performance settings
  performance:
    max_concurrent_optimizations: 5
    optimization_timeout: 1800
    memory_limit: "3GB"
    evaluation_interval: 300

# AI/ML Libraries Configuration
ai_ml_libraries:
  # PyTorch settings
  pytorch:
    enabled: true
    version: "2.0.0"
    device: "auto"  # auto, cpu, cuda, mps
    mixed_precision: true
    compile: true
  
  # Transformers settings
  transformers:
    enabled: true
    cache_dir: "./cache/transformers"
    model_max_length: 512
  
  # Sentence Transformers settings
  sentence_transformers:
    enabled: true
    cache_dir: "./cache/sentence_transformers"
    device: "auto"
  
  # Quantum libraries
  quantum:
    qiskit:
      enabled: true
      version: "0.45.0"
      backend: "qasm_simulator"
    cirq:
      enabled: false
      version: "1.0.0"
    pennylane:
      enabled: false
      version: "0.32.0"

# Database Configuration
database:
  # Primary database
  primary:
    type: "sqlite"
    path: "./data/ai_orchestration.db"
    pool_size: 10
    max_overflow: 20
  
  # Cache database
  cache:
    type: "redis"
    host: "localhost"
    port: 6379
    db: 0
    password: null
    max_connections: 10

# Monitoring Configuration
monitoring:
  enabled: true
  
  # Metrics collection
  metrics:
    collection_interval: 30  # seconds
    retention_days: 30
    export_format: "prometheus"
  
  # Health checks
  health_checks:
    enabled: true
    interval: 60  # seconds
    timeout: 10
    endpoints:
      - "/health"
      - "/health/quantum"
      - "/health/meta_learning"
      - "/health/ensemble"
      - "/health/continual_learning"
      - "/health/optimization"
  
  # Alerting
  alerting:
    enabled: true
    thresholds:
      cpu_usage: 80
      memory_usage: 85
      error_rate: 5
      response_time: 1000  # milliseconds

# Security Configuration
security:
  # Authentication
  authentication:
    enabled: true
    method: "jwt"
    secret_key: "your-secret-key-here"
    token_expiry: 3600  # seconds
  
  # Authorization
  authorization:
    enabled: true
    roles:
      - "admin"
      - "user"
      - "readonly"
  
  # API security
  api_security:
    rate_limiting:
      enabled: true
      requests_per_minute: 100
    cors:
      enabled: true
      allowed_origins: ["*"]
    ssl:
      enabled: false
      cert_file: null
      key_file: null

# External Services Configuration
external_services:
  # AI/ML APIs
  ai_apis:
    openai:
      enabled: false
      api_key: null
      model: "gpt-4"
    anthropic:
      enabled: false
      api_key: null
      model: "claude-3"
    huggingface:
      enabled: true
      api_key: null
      model_hub: "https://huggingface.co"
  
  # Quantum computing services
  quantum_services:
    ibm_quantum:
      enabled: false
      api_token: null
      hub: "ibm-q"
      group: "open"
      project: "main"
    google_quantum:
      enabled: false
      project_id: null
      location: "us-central1"
  
  # Cloud services
  cloud_services:
    aws:
      enabled: false
      access_key: null
      secret_key: null
      region: "us-east-1"
    gcp:
      enabled: false
      service_account_key: null
      project_id: null
    azure:
      enabled: false
      connection_string: null

# Development Configuration
development:
  debug: false
  hot_reload: false
  profiling: false
  
  # Testing
  testing:
    enabled: true
    test_data_dir: "./tests/data"
    mock_external_services: true
  
  # Documentation
  documentation:
    enabled: true
    auto_generate: true
    output_dir: "./docs"




